{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network To Predict Incubator Temperature\n",
    "\n",
    "In this notebook we give you an example on how to train a neural network to predict the incubator temperature, from previous temperatures as well as control commands.\n",
    "\n",
    "The network therefore has a similar interface to the incubator FMU created in previous notebooks.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The following is the dataset we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CSV file from an incubator dataset\n",
    "import os\n",
    "\n",
    "# Get the current working directory.\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "assert os.path.basename(current_dir) == '3-Physics-Modelling', 'Current directory is not 3-Physics-Modelling'\n",
    "\n",
    "# Get the parent directory. Should be the root of the repository\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# The root of the repo should contain the incubator_dt folder. Otherwise something went wrong in 0-Pre-requisites.\n",
    "assert os.path.exists(os.path.join(parent_dir, 'incubator_dt')), 'incubator_dt folder not found in the repository root'\n",
    "\n",
    "csv_file_path = os.path.join(parent_dir, 'incubator_dt', 'software', 'incubator', 'datasets', '20230501_calibration_empty_system', '20230501_calibration_empty_system.csv')\n",
    "\n",
    "assert os.path.exists(csv_file_path), '20230501_calibration_empty_system.csv not found in the incubator repository.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(csv_file_path)\n",
    "data['heater_on_int'] = data['heater_on'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create subplots to visualize the temperature and the control signal (heater) over time. This helps us understand how the data behaves and how the heater's state affects the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with shared X-axis for temperature and control signal.\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 6))\n",
    "\n",
    "# Plot temperature data on the first subplot\n",
    "ax1.plot(data.index, data.average_temperature, label='Temperature')\n",
    "ax1.plot(data.index, data.t3, label='Room Temperature')\n",
    "ax1.set_ylabel('Temperature (°C)')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot control signal data on the second subplot (heater on/off)\n",
    "ax2.plot(data.index, data.heater_on, label='Heater')\n",
    "ax2.plot(data.index, data.heater_on_int, label='Heater (int)', linestyle='--')  # Verification\n",
    "ax2.set_xlabel('Samples')\n",
    "ax2.set_ylabel('Control Signal')\n",
    "ax2.legend()\n",
    "\n",
    "# Add a title to the shared X-axis\n",
    "fig.suptitle('Temperature and Control Signal Over Time')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "### Problem Overview\n",
    "The goal of the neural network is to predict the **next temperature** of a system based on historical data. In this case, the system measures:\n",
    "- **Average temperature (`average_temperature`)**: This is the main feature we are trying to predict for the next time step.\n",
    "- **Room temperature (`t3`)**: This is the ambient room temperature, which may influence the system’s temperature.\n",
    "- **Heater state (`heater_on`)**: This binary value indicates whether the heater is on (1) or off (0), affecting how the temperature evolves.\n",
    "\n",
    "We use these variables at a given time (let's call it time `t`) to predict the temperature at the next time step (`t+1`).\n",
    "\n",
    "#### Inputs of the Neural Network\n",
    "The neural network takes in **three inputs** at each time step `t` to make the prediction for time `t+1`:\n",
    "\n",
    "1. **`previous_T` (previous average temperature)**:  \n",
    "   This is the temperature of the system at time `t`. It captures the state of the system at the current time step. The neural network uses this to infer how much the temperature is likely to change.\n",
    "\n",
    "2. **`previous_RoomT` (previous room temperature)**:  \n",
    "   This is the room (ambient) temperature at time `t`. Since external conditions affect the temperature inside the system, knowing the room temperature helps the neural network understand the external environment's influence on the system.\n",
    "\n",
    "3. **`previous_H` (previous heater state)**:  \n",
    "   This is a binary feature indicating whether the heater was ON or OFF at time `t`. It has a significant impact on temperature dynamics since the heater increases the system’s temperature when ON. The neural network will learn how the heater state influences temperature changes.\n",
    "\n",
    "These three input features form a **3-dimensional vector** representing the system's state at time `t`.\n",
    "\n",
    "#### Outputs of the Neural Network\n",
    "The neural network produces **one output**:\n",
    "\n",
    "- **`next_T` (next average temperature)**:  \n",
    "  This is the predicted average temperature at time `t+1`. The goal of the neural network is to learn the relationship between the current system state (given by the three input features) and the future temperature, so it can make accurate predictions.\n",
    "\n",
    "Thus, the neural network's job is to map the input vector `[previous_T, previous_RoomT, previous_H]` to a scalar output `next_T`, which represents the system's temperature at the next time step.\n",
    "\n",
    "#### Why These Inputs and Outputs?\n",
    "- **Historical temperature**: The temperature of a system tends to evolve gradually, meaning that the current temperature is likely a good indicator of what the temperature will be in the near future. This is why `previous_T` is used as an input.\n",
    "  \n",
    "- **Room temperature**: If the room temperature is significantly different from the system’s temperature, it could cause the system’s temperature to change more rapidly (e.g., cooling down when the room is cold). Therefore, including `previous_RoomT` helps the model learn how external conditions affect the system.\n",
    "\n",
    "- **Heater state**: The heater directly affects the temperature. When it’s on, the system’s temperature increases. By including `previous_H`, the model learns how much the heater impacts the temperature changes.\n",
    "\n",
    "#### Neural Network Architecture\n",
    "In this case, the architecture is a simple **linear regression model**:\n",
    "\n",
    "- **Input layer**: Takes the three features `[previous_T, previous_RoomT, previous_H]`.\n",
    "- **Output layer**: Produces a single output, which is the predicted `next_T` (the temperature at the next time step).\n",
    "\n",
    "### Preparing the Dataset for Training\n",
    "\n",
    "To make predictions, we need to use past data to predict future data. Here we shift the data to create input-output pairs: \n",
    "- The input (`previous_T`) is the temperature at time `t`.\n",
    "- The output (`next_T`) is the temperature at time `t+1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data with shifted time series\n",
    "nn_data = pd.DataFrame()\n",
    "\n",
    "# Use previous temperature, room temperature, and heater state as inputs\n",
    "nn_data['previous_T'] = data.loc[0:data.index[-2], 'average_temperature']\n",
    "nn_data['previous_RoomT'] = data.loc[0:data.index[-2], 't3']\n",
    "nn_data['previous_H'] = data.loc[0:data.index[-2], 'heater_on_int']\n",
    "\n",
    "# The target is the next temperature\n",
    "nn_data['next_T'] = data.loc[1:data.index[-1], 'average_temperature'].to_numpy()\n",
    "\n",
    "# Verify that the data is aligned correctly\n",
    "for i in range(0, nn_data.index[-2]):\n",
    "    assert nn_data.loc[i+1,'previous_T'] == nn_data.loc[i,'next_T']\n",
    "\n",
    "nn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data into Training and Testing Sets\n",
    "\n",
    "We split the data into training and testing sets to evaluate the model's performance. Typically, around 70% of the data is used for training, and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = int(0.3 * len(nn_data))\n",
    "training_data = nn_data.iloc[:-rows_to_drop]\n",
    "test_data = nn_data.iloc[-rows_to_drop:]\n",
    "\n",
    "# Verify that the split was done correctly\n",
    "assert len(training_data) + len(test_data) == len(nn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Data to Tensors for PyTorch\n",
    "\n",
    "PyTorch models require input data in the form of tensors. We convert the input features (`previous_T`, `previous_RoomT`, `previous_H`) and the target (`next_T`) into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to convert pandas DataFrame into PyTorch tensors\n",
    "def convert_to_torch_inputs_outputs(df):\n",
    "    X = torch.tensor(df[['previous_T', 'previous_RoomT', 'previous_H']].values, dtype=torch.float32)\n",
    "    Y = torch.tensor(df[['next_T']].values, dtype=torch.float32)\n",
    "    return X, Y\n",
    "\n",
    "# Convert training data to tensors\n",
    "X_train, Y_train = convert_to_torch_inputs_outputs(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network model (a simple linear regression model)\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)  # 3 input features and 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize the model and define the loss function (Mean Squared Error)\n",
    "model = LinearRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Adam optimizer and train the model for 5000 epochs, updating the model’s parameters to minimize the loss (Mean Squared Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 5000  # Number of epochs to train\n",
    "\n",
    "# Define the loss function (Mean Squared Error)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  # Zero out gradients\n",
    "    outputs = model(X_train)  # Forward pass\n",
    "    loss = loss_fn(outputs, Y_train)  # Compute the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    \n",
    "    optimizer.step()  # Update model parameters\n",
    "\n",
    "    # Print loss periodically for monitoring\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the weights and bias for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.children():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(layer.state_dict()['weight'])\n",
    "        print(layer.state_dict()['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions and Visualizing Results\n",
    "\n",
    "We use the trained model to predict the next temperature for the entire dataset. Then we compare the predicted values with the actual ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the full dataset to tensors and predict temperatures\n",
    "X_full, _ = convert_to_torch_inputs_outputs(nn_data)\n",
    "nn_data['next_T_predicted'] = model(X_full).detach().numpy()\n",
    "\n",
    "# Plot actual vs. predicted temperatures\n",
    "plt.plot(nn_data.index, nn_data.next_T, label='Actual Temperature')\n",
    "plt.plot(nn_data.index, nn_data.next_T_predicted, label='Predicted Temperature', linestyle='--')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.xlabel('Samples')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### So... what have we done? \n",
    "\n",
    "We have trained a neural network (NN) that is capable of predicting the next temperature from a given previous temperature examples as well as control actuation.\n",
    "This approach is very easy but has severe drawbacks when compared to building an ODE model as in the previous notebooks:\n",
    "1. The NN has no notion of parameters so it is intimately tied to the physical incubator used to generate the dataset. Change the incubator box for instance, and a new data set would have to be generated for that new incubator to retrain the NN. To be fair, for the ODE model we would also have to find the new values for the parameters that correspond to the new box (we will talk about model calibration later in the course).\n",
    "2. The NN does not predict the heater temperature like the ODE does. It's simply non existant since it's not on the dataset.\n",
    "3. The NN assumes a fixed timestep corresponding to the timestep of the dataset samples.\n",
    "4. The NN should not be used in a closed loop simulation when we where we couple the controller with the NN. This is because in such a scenario the predictions of the network actually have to make it back to the inputs of the network as previous temperature readings. This means that any errors made in the predictions tend to accumulate over time, leading to excessively high prediction errors. This does not happen in the ODE model because the numerical solver uses clever tricks to prevent excessive accumulation of error over time. An example is given below to illustrate how bad the predictions become over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code uses the model in a closed loop to conduct a simulation and compares the result of simulatio with the real data.\n",
    "\n",
    "# Create a tensor object that will be used to store the inputs of the model\n",
    "input = torch.randn(1, 3)\n",
    "\n",
    "simulated_T = nn_data.loc[0].previous_T\n",
    "simulated_Ts = []  # Keep predictions in a simple list\n",
    "\n",
    "for step in nn_data.index:\n",
    "\n",
    "  # Prepare inputs for the model\n",
    "  input[0,0] = simulated_T  # corresponds to previous_T, but since we are making simulation it will be a previous model output\n",
    "  input[0,1] = nn_data.loc[step]['previous_RoomT']\n",
    "  input[0,2] = nn_data.loc[step]['previous_H']\n",
    "\n",
    "  output = model(input).detach().numpy()\n",
    "\n",
    "  simulated_T = float(output[0,0])\n",
    "  simulated_Ts.append(simulated_T)\n",
    "\n",
    "# Add the simulation to the nice table\n",
    "nn_data[\"T_simulation\"] = simulated_Ts\n",
    "nn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot previous simulation\n",
    "plt.plot(nn_data.index, nn_data.next_T, label='Temperature')\n",
    "plt.plot(nn_data.index, nn_data.T_simulation, label='Simulation of Temperature')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.xlabel('Samples')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the results are less than ideal! Spend some time analyzing the differences between the above \"close loop simulation\" use case of the neural network with the previous \"one step prediction\" use case, where the neural network performed a lot better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then... what can the NN be used for?\n",
    "\n",
    "A neural network trained as in the above scenario is ideal for building a digital twin monitoring service. \n",
    "Recall that earlier you have deployed a MovingAverageTemperatureService. \n",
    "In the next notebook, we will do the same, except instead of a moving average, we will use the NN to predict the next temperature, and the PTReconfigurationService will use the differences between the prediction and actual to reconfigure the controller when the lid is open.\n",
    "\n",
    "Before we move on, let us store our trained model and create a few python scripts that will be used in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic consistency check to see if above is still consistent with previous notebooks.\n",
    "current_dir = os.getcwd()\n",
    "assert os.path.basename(current_dir) == '3-Physics-Modelling', 'Current directory is not 3-Physics-Modelling'\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "assert os.path.exists(os.path.join(parent_dir, '1-Incubator-Service', '3-PTReconfigurationService.ipynb')), '3-PTReconfigurationService.ipynb folder not found in the repository'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store trained model parameters\n",
    "\n",
    "# Define a path to save the model\n",
    "model_save_path = \"temperature_prediction_model.pth\"\n",
    "\n",
    "# Save the trained model's state dictionary (the model's learned parameters)\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile temperature_prediction_model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network model (a simple linear regression model). Note that this much match the model architecture used in training\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)  # 3 input features and 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class IncubatorPredictionNN:\n",
    "    def __init__(self, model_path='temperature_prediction_model.pth'):\n",
    "        # Instantiate the model\n",
    "        self.model = LinearRegression()\n",
    "\n",
    "        # Load the saved state dictionary into the model\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        # Set the model to evaluation mode (important for inference)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.Tb = 0.0\n",
    "\n",
    "    def predict_Tb(self, Tb, Tr, H_h):\n",
    "        # Prepare the inputs to the NN model\n",
    "        nn_input = torch.tensor([[Tb, Tr, H_h]], dtype=torch.float32)\n",
    "\n",
    "        # Make the prediction with the neural network\n",
    "        with torch.no_grad():  # No need to compute gradients during inference\n",
    "            self.Tb = self.model(nn_input).item()\n",
    "    \n",
    "    def get_Tb(self):\n",
    "        return self.Tb\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the incubator prediction model\n",
    "    # This will load the neural network model from 'temperature_prediction_model.pth'\n",
    "    model_path = 'temperature_prediction_model.pth'\n",
    "    incubator_nn = IncubatorPredictionNN(model_path)\n",
    "\n",
    "    # Provide a set of inputs: \n",
    "    # Tb: the current box temperature,\n",
    "    # Tr: the room temperature,\n",
    "    # H_h: the heater state (1 for ON, 0 for OFF)\n",
    "    current_Tb = 25.0  # Current box temperature (in °C)\n",
    "    room_Temp = 22.0   # Room temperature (in °C)\n",
    "    heater_state = 1   # Heater state (1: ON, 0: OFF)\n",
    "\n",
    "    # Predict the next box temperature based on the input data\n",
    "    incubator_nn.predict_Tb(current_Tb, room_Temp, heater_state)\n",
    "\n",
    "    # Retrieve and print the predicted temperature\n",
    "    predicted_Tb = incubator_nn.get_Tb()\n",
    "    print(f\"Predicted next box temperature: {predicted_Tb:.2f} °C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Run the script and capture the output\n",
    "result = subprocess.run(\n",
    "    [sys.executable, 'temperature_prediction_model.py'], \n",
    "    stdout=subprocess.PIPE, \n",
    "    stderr=subprocess.PIPE,  # Capture standard error\n",
    "    text=True,               # Ensures the output is returned as a string, not bytes\n",
    "    encoding='utf-8',        # Specify the encoding (change if necessary)\n",
    "    check=True  # Raise an error if the subprocess fails\n",
    "    )\n",
    "\n",
    "# Print the output from the script\n",
    "print(result.stdout)\n",
    "\n",
    "# Print any errors if there are any\n",
    "if result.stderr:\n",
    "    print(\"Errors: \", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. In your own words, what are two advantages and two disadvantages for the NN approach, and for the ODE approach?\n",
    "2. Consider building a new service for a system. Given some data, and access to a domain expert who can provide the ODE approach, how should we proceed? Which one should we start with, or should we do them in parallel? Does one validate the other? Discuss.\n",
    "3. Find the cell where we printed the weights and biases for the NN model.\n",
    "  a. Relate these numbers to the input data. What does the model think is the most important variable for predicting the next temperature value? Can any other domain knowledge be extracted from this model?\n",
    "  b. Return to the ODE equations from the previous notebook. What domain knowledge is encoded in these equations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to test, run the above script in a new terminal:\n",
    "```bash\n",
    "python temperature_prediction_model.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
