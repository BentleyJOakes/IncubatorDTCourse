{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Optimization Problems with Python\n",
    "\n",
    "The `scipy.optimize.least_squares` function in Python is a powerful tool for solving optimization problems. It provides a range of algorithms to minimize scalar functions of one or more variables. This tutorial will guide you through the process of using `least_squares` to solve optimization problems step-by-step.\n",
    "\n",
    "For more details, check the official [SciPy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Make sure you have `scipy` installed. If not, you can install it using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Modules\n",
    "\n",
    "Start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Objective Function\n",
    "\n",
    "Define the function you want to minimize. For example, let's minimize the following quadratic function:\n",
    "\n",
    "$$\n",
    "    f(x) = (x - 3)^2 + 4\n",
    "$$\n",
    "\n",
    "Here is the corresponding Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x):\n",
    "    return (x - 3)**2 + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Function\n",
    "\n",
    "Before running the optimization, it's often helpful to visualize the function. You can use `matplotlib` to plot the function over a range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of x values\n",
    "x = np.linspace(-2, 8, 500)\n",
    "y = (x - 3)**2 + 4\n",
    "\n",
    "# Plot the function\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label=\"f(x) = (x - 3)^2 + 4\")\n",
    "plt.scatter(3, 4, color='red', label=\"Minimum Point (3, 4)\")\n",
    "plt.title(\"Objective Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set an Initial Guess\n",
    "\n",
    "Provide an initial guess for the solution. This is a required parameter for `least_squares`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guess = [0]  # Starting point for the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Call the `least_squares` Function\n",
    "\n",
    "Use the `least_squares` function to solve the optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = least_squares(objective_function, initial_guess)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `scipy.optimize.least_squares` provides information about the optimization process and the final solution found. Here\u2019s what each field means in your output:\n",
    "\n",
    "1. **`xtol` termination condition is satisfied.**\n",
    "   - This means the optimization stopped because the change in the solution `x` was below the tolerance (`xtol`). The optimizer considers the solution sufficiently accurate.\n",
    "\n",
    "2. **`success: True`**\n",
    "   - The optimization was successful, meaning it found a solution within the given tolerances.\n",
    "\n",
    "3. **`status: 3`**\n",
    "   - The termination reason:\n",
    "     - `1`: Stopped because `gtol` (gradient tolerance) was met.\n",
    "     - `2`: Stopped because `ftol` (cost function tolerance) was met.\n",
    "     - `3`: Stopped because `xtol` (change in `x` was small enough) was met.\n",
    "     - Our case: `status = 3` \u2192 the solution changed very little between iterations.\n",
    "\n",
    "4. **`fun: [ 4.000e+00]`**\n",
    "   - The residual (difference between the function's output and the expected value). In our case, the function value at the final solution is `4.0`.\n",
    "\n",
    "5. **`x: [ 3.000e+00]`**\n",
    "   - The optimal parameter found: `x = 3.0`.\n",
    "\n",
    "6. **`cost: 8.0`**\n",
    "   - The sum of squared residuals: `cost = 0.5 * ||fun||\u00b2 = 0.5 * (4\u00b2) = 8.0`.\n",
    "\n",
    "7. **`jac: [[ 3.974e-08]]`**\n",
    "   - The Jacobian matrix at the solution, representing the rate of change of the function with respect to `x`.\n",
    "\n",
    "8. **`grad: [ 1.589e-07]`**\n",
    "   - The gradient of the cost function at `x = 3.0`. This is very small, indicating that we are near a local minimum.\n",
    "\n",
    "9. **`optimality: 1.5894571940104166e-07`**\n",
    "   - This is the norm of the gradient, which is close to zero, meaning the solution is near an optimal point.\n",
    "\n",
    "10. **`active_mask: [ 0.000e+00]`**\n",
    "    - Indicates constraints on the variables. A value of `0` means that no constraints are active at the solution.\n",
    "\n",
    "11. **`nfev: 17`**\n",
    "    - The number of function evaluations during optimization (how many times the function was called).\n",
    "\n",
    "12. **`njev: 3`**\n",
    "    - The number of Jacobian evaluations (how many times the derivative was computed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze the Results\n",
    "\n",
    "You can extract the optimized parameters and the minimum value of the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized Parameters:\", result.x)\n",
    "print(\"Minimum Value:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Constraints\n",
    "\n",
    "`least_squares` also allows you to include constraints. For example, to add bounds or equality/inequality constraints:\n",
    "\n",
    "### Example with Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function we want to minimize\n",
    "def func(x):\n",
    "    return -(x**2 - 4)  # We want to find x such that this function is close to zero\n",
    "\n",
    "# Set an initial guess\n",
    "x0 = 1.1 \n",
    "\n",
    "# Define the bounds: lower bound of 1, upper bound of 5\n",
    "bounds = (1, 5)\n",
    "\n",
    "# Call least_squares with bounds\n",
    "result = least_squares(func, x0, bounds=bounds)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimization result:\")\n",
    "print(result)\n",
    "\n",
    "# Plot the function\n",
    "x = np.linspace(-2, 2, 500)\n",
    "y = -(x**2 - 4)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label=\"f(x) = -(x^2 - 4)\")\n",
    "plt.scatter(result.x, result.fun, color='red', label=\"Minimum Point\")\n",
    "plt.title(\"Objective Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizing a Function with Two Parameters\n",
    "\n",
    "Consider a function with two parameters:\n",
    "\n",
    "$$\n",
    "    f(x, y) = (x - 1)^2 + (y - 2)^2\n",
    "$$\n",
    "\n",
    "This function has a minimum at $(x, y) = (1, 2)$. Here's how to minimize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_2d(vars):\n",
    "    x, y = vars\n",
    "    return (x - 1)**2 + (y - 2)**2\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [0, 0]\n",
    "\n",
    "# Perform optimization\n",
    "result = least_squares(objective_function_2d, initial_guess)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimized Parameters:\", result.x)\n",
    "print(\"Minimum Value:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Function\n",
    "\n",
    "For two variables, you can visualize the function as a contour plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_trace_x = []\n",
    "optimizer_trace_y = []\n",
    "\n",
    "def objective_function_2d(vars):\n",
    "    x, y = vars\n",
    "    optimizer_trace_x.append(x)\n",
    "    optimizer_trace_y.append(y)\n",
    "    return (x - 1)**2 + (y - 2)**2\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [0, 0]\n",
    "\n",
    "# Perform optimization\n",
    "result = least_squares(objective_function_2d, initial_guess)\n",
    "\n",
    "x = np.linspace(-1, 3, 100)\n",
    "y = np.linspace(0, 4, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = (x - 1)**2 + (y - 2)**2\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contour(x, y, z, levels=20, cmap='viridis')\n",
    "plt.scatter(optimizer_trace_x, optimizer_trace_y, alpha=0.5, label=\"Optimizer Trace\")\n",
    "plt.scatter(1, 2, color='red', label=\"Minimum Point (1, 2)\")\n",
    "plt.title(\"Objective Function: Contour Plot\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. When setting bounds on the optimization, an incorrect optimization parameter was returned. What should we check for when setting bounds?\n",
    "2. The optimal parameters found above are not whole numbers (integers). Why do you think this is? Should we \"clean up\" these numbers? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}